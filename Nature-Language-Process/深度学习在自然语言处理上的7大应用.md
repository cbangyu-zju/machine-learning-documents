## 深度学习在自然语言处理上的7大应用
本论文翻译，摘抄自[AI前线](https://36kr.com/p/5112141.html)，[英文版](https://machinelearningmastery.com/applications-of-deep-learning-for-natural-language-processing/)

自然语言中仍然存在许多具有挑战性的问题。然而，深度学习方法在某些特定的语言问题上可以获得最先进的结果。最有趣的不仅仅是深度学习模型在基准问题上的性能；事实上，一个单一的模型可以学习单词的意思和执行语言任务，从而避免需要一套专门的和手工的方法。在这篇文章中，你将发现 7 种有趣的自然语言处理任务，其中深度学习方法正在取得一些进展。

## 概述
在此文中，我们将看看下面的 7 种自然语言处理问题。

* 文本分类
* 语言模型
* 语音识别
* 说明生成
* 机器翻译
* 文本摘要
* 问答系统

## 文本分类
对于给定的文本例子，预测一个预先定义的类标签。

文本分类的目标是对文档的主题或主旨进行分类。— 第 575 页，Foundations of Statistical Natural Language Processing，1999。情感分析是很流行的一个分类例子，其中类标签代表源文本的情感色调，如“积极的”或“消极的“。

下面有 3 个例子：

* 垃圾邮件过滤，将电子邮件文本分类为垃圾邮件或非垃圾邮件。
* 语言识别，对源文本的语言类型进行分类。
* 流派分类，对虚构故事的流派进行分类。

此外，该问题也可能需要给一个文本分配多个类标签，即所谓的多标签分类。譬如，预测源推文的多个主题标签。更多信息可参考：1. Scholarpedia 上的 Text categorization；2. 维基百科上的 Document classification。下面3篇是讲深度学习用于文本分类：

1. Deep Unordered Composition Rivals Syntactic Methods for Text Classification，2015；
2. Effective Use of Word Order for Text Categorization with Convolutional Neural Networks，2015；
3. Convolutional Neural Networks for Sentence Classification，2014

## 语言模型
语言模型是很多有趣的自然语言问题的子任务，特别是那些根据输入调节语言模型的问题。

这个问题是在已知前几个的单词的情况下预测下一个词。该任务对语音或光学字符识别非常重要，也被用于拼写检查、手写识别和统计机器翻译。— 第 191 页, Foundations of Statistical Natural Language Processing，1999。

语言模型不仅在学术界引起很大的兴趣，它还是许多深度学习自然语言处理软件架构中的重要组成部分。语言模型学习词之间的概率关系，从而生成与源文本统计一致的新词序列。单独来看，语言模型可被用于文本或语音生成，譬如：1. 生成新的文章标题；2. 生成新的句子、段落或文档；3. 生成建议的句子延续。可参考的论文如下：

1. The Unreasonable Effectiveness of Recurrent Neural Networks，2015；
2. Generative Model-Based Text-to-Speech Synthesis，Lecture 10，Oxford，2017
3. A Neural Probabilistic Language Model，2003

## 语音识别
语音识别指的是识别出人们所说的每一个字。

语音识别的任务在于，将包含自然语言话语的声学信号映射到与说话者预期的相应的单词序列中。— 第 458 页，Deep Learning，2016。

给定发声的文本作为音频数据，该模型必须产生人类可读的文本。鉴于该过程的自动性质，该问题也可被称为自动语音识别（ASR）。语言模型被用于创建基于音频数据的文本输出。例子包括：1. 演讲速记；2. 为电影或电视节目创建文字标题；3. 在开车时向收音机发出指令。可参考的论文如下：

1. Connectionist Temporal Classification: Labelling Unsegmented Sequence Data with Recurrent Neural Networks，2006。
2. Speech Recognition with Deep Recurrent Neural Networks，2013。
3. Exploring convolutional neural network structures and optimization techniques for speech recognition，2014。

## 说明生成
说明生成指的是描述图片内容的一类问题。即，给定一个数字图像，如图片，生成关于该图像内容的文字描述。

语言模型被用于创建基于图像的说明。例子包括：1. 描述场景内容；2. 为图片生成说明；3. 描述视频。这不仅能用于帮助听力障碍者，也能帮我们把网络上搜索到的图像和视频数据生成人类可读的文本。可参考的论文如下：

1. Show, Attend and Tell: Neural Image Caption Generation with Visual Attention，2016
2. Show and tell: A neural image caption generator，2015
3. Sequence to Sequence – Video to Text，2015

## 机器翻译
机器翻译解决将一种语言的源文本转换为另一种语言的问题。

机器翻译将文本或语音从一种语言自动翻译成另一种语言，它是 NLP 最重要的应用之一。— 第 463 页，Foundations of Statistical Natural Language Processing，1999。

鉴于使用了深层神经网络，该领域被称为神经机器翻译。

在机器翻译任务中，输入已经由某种语言的符号序列组成，计算机程序必须将其转换为另一种语言的一系列符号。这通常适用于自然语言，譬如从英语翻译成法语。深度学习最近开始对这种任务产生重要影响。

— 第 98 页，Deep Learning，2016。

基于源文本，语言模型用于输出以第二语言表示的目标文本。机器翻译的例子包括：1. 将法文文档翻译成英文；2. 将西班牙语语音翻译为德文文本；3. 将英文文本翻译为意大利语语音。可参考的论文如下：

1. Sequence to Sequence Learning with Neural Networks，2014
2. Neural Machine Translation by Jointly Learning to Align and Translate，2014
3. Joint Language and Translation Modeling with Recurrent Neural Networks，2013

## 文本摘要
文本摘要的任务是为文本文档创建短的描述。

如上所述，应用一个语言模型来输出对全文档的总结。文本摘要的例子包括：1. 为文档创建标题；2. 为文档创建摘要。可参考的论文如下：

1. A Neural Attention Model for Abstractive Summarization，2015
2. Abstractive Text Summarization Using Sequence-to-Sequence RNNs and Beyond，2016
3. Neural Summarization by Extracting Sentences and Word，2016

## 问答系统
问答系统要解决的问题是，给出一个主题（如文本文档），回答有关该主题的具体问题。

… 问答系统尝试通过返回适当的名词短语（例如位置、人物或日期）来回答以问题形式提出的用户查询。譬如，“为什么刺杀肯尼迪总统？”，问答系统可能用名词短语 Oswald 来回答。— 第 377 页，Foundations of Statistical Natural Language Processing，1999。

问答系统的例子包括：1. 回答有关维基百科文章的问题；2. 回答有关新闻文章的问题；3. 回答有关医疗记录的问题。可参考的论文如下：

1. Teaching Machines to Read and Comprehend，2015
2. Question Answering over Freebase with Multi-Column Convolutional Neural Networks，2015
3. Deep Learning for Answer Sentence Selection，2015

## 进一步阅读
如果你想更深入地了解深度学习在 NLP 上的应用，下面列出了一些阅读资料。

1. A Primer on Neural Network Models for Natural Language Processing，2015
2. Natural Language Processing (almost) from Scratch，2011
3. Deep Learning for Natural Language Processing，Practicals Overview，Oxford，2017
4. What NLP problems has deep learning or neural networks been applied to successfully?
5. Can deep learning make similar breakthroughs in natural language processing as it did in vision & speech?











